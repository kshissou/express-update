import requests
from bs4 import BeautifulSoup
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
import os
import json

# ========== é…ç½® ==========
SPREADSHEET_NAME = "express-claim-app"
MAIN_SHEET = "Sheet1"

cookie_string = os.environ.get("YUANRI_COOKIE", "")
json_str = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS_JSON", "")

URL = "http://www.yuanriguoji.com/Phone/Package"
HEADERS = {
    "User-Agent": "Mozilla/5.0",
    "Cookie": cookie_string
}

# ========== å‡½æ•°å®šä¹‰ ==========

def get_gsheet():
    scopes = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
    info = json.loads(json_str)
    creds = Credentials.from_service_account_info(info, scopes=scopes)
    client = gspread.authorize(creds)
    return client

def fetch_packages():
    res = requests.get(URL, headers=HEADERS)
    soup = BeautifulSoup(res.text, "html.parser")
    inputs = soup.find_all("input", class_="chk_select")

    records = []
    for tag in inputs:
        pkg_id = tag.get("value")
        weight = tag.get("data-weight", "0")
        span = soup.find("span", {"name": "BillCode", "data-id": pkg_id})
        if span:
            tracking = span.text.strip()

            # æŸ¥æ‰¾å…¥åº“æ—¶é—´ï¼ˆåˆ°åº“æ—¶é—´ï¼‰
            p_tag = soup.find("p", class_="more_massage Hide_" + pkg_id)
            ruku_time = ""
            if p_tag:
                span_texts = p_tag.find_all("span", class_="SpanTextLang")
                for s in span_texts:
                    if s.previous_sibling and "åˆ°åº“æ—¶é—´" in s.previous_sibling.text:
                        ruku_time = s.text.strip()
                        break
                if not ruku_time and span_texts:
                    ruku_time = span_texts[0].text.strip()

            records.append({
                "å¿«é€’å•å·": tracking,
                "é‡é‡ï¼ˆkgï¼‰": weight,
                "è°çš„å¿«é€’": "",
                "åˆ°åº“æ—¶é—´": ruku_time
            })

    return pd.DataFrame(records)

def update_main_sheet(new_df):
    client = get_gsheet()
    sheet = client.open(SPREADSHEET_NAME).worksheet(MAIN_SHEET)
    existing = pd.DataFrame(sheet.get_all_records())

    columns = ["å¿«é€’å•å·", "é‡é‡ï¼ˆkgï¼‰", "è°çš„å¿«é€’", "åˆ°åº“æ—¶é—´"]
    for col in columns:
        if col not in existing.columns:
            existing[col] = ""
        if col not in new_df.columns:
            new_df[col] = ""

    existing["å¿«é€’å•å·"] = existing["å¿«é€’å•å·"].astype(str)
    new_df["å¿«é€’å•å·"] = new_df["å¿«é€’å•å·"].astype(str)

    existing_ids = set(existing["å¿«é€’å•å·"])
    new_entries = new_df[~new_df["å¿«é€’å•å·"].isin(existing_ids)]

    print(f"ğŸ“¦ æŠ“å–åˆ°çš„æ‰€æœ‰å•å·ï¼š {list(new_df['å¿«é€’å•å·'])}")
    print(f"ğŸ“„ è¡¨ä¸­å·²æœ‰å•å·ï¼š {list(existing['å¿«é€’å•å·'])}")

    if new_entries.empty:
        print("ğŸ“­ æ²¡æœ‰æ–°å¢è®°å½•ï¼Œè·³è¿‡æ›´æ–° âœ…")
        return

    updated = pd.concat([existing, new_entries], ignore_index=True)
    updated = updated[columns]
    sheet.clear()
    sheet.update([columns] + updated.values.tolist())
    print(f"âœ… å·²æ–°å¢ {len(new_entries)} æ¡è®°å½•ï¼Œå¹¶æ›´æ–° Google Sheets âœ…")

# ========== ä¸»æµç¨‹ ==========
def main():
    print("ğŸšš æŠ“å–å¿«é€’æ•°æ®ä¸­...")
    df = fetch_packages()
    print(f"ğŸ“¦ å…±è·å– {len(df)} æ¡å¿«é€’è®°å½•")
    if df.empty:
        print("âš ï¸ æœªæŠ“å–åˆ°ä»»ä½•è®°å½•ï¼Œè¯·æ£€æŸ¥ Cookie æˆ–é¡µé¢ç»“æ„")
        return
    update_main_sheet(df)
    print("âœ… Google Sheets å·²æ›´æ–°")

if __name__ == "__main__":
    main()
