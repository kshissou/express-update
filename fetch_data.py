import requests
from bs4 import BeautifulSoup
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
import os
import json

# ========== é…ç½® ==========
SPREADSHEET_NAME = "express-claim-app"
MAIN_SHEET = "Sheet1"

cookie_string = os.environ.get("YUANRI_COOKIE", "")
json_str = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS_JSON", "")

# ä¿®å¤ï¼šæŠ“å–â€œå…¨éƒ¨â€çŠ¶æ€çš„é¡µé¢
URL = "http://www.yuanriguoji.com/Phone/Package"
HEADERS = {
    "User-Agent": "Mozilla/5.0",
    "Cookie": cookie_string
}

# ========== è·å– Google Sheets å®¢æˆ·ç«¯ ==========
def get_gsheet():
    scopes = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
    info = json.loads(json_str)
    creds = Credentials.from_service_account_info(info, scopes=scopes)
    client = gspread.authorize(creds)
    return client

# ========== æŠ“å–é¡µé¢ä¸­çš„å¿«é€’è®°å½• ==========
def fetch_packages():
    res = requests.get(URL, headers=HEADERS)
    soup = BeautifulSoup(res.text, "html.parser")
    inputs = soup.find_all("input", class_="chk_select")

    records = []
    for tag in inputs:
        pkg_id = tag.get("value")
        weight = tag.get("data-weight", "0")
        span = soup.find("span", {"name": "BillCode", "data-id": pkg_id})
        if not span:
            continue
        tracking = span.text.strip()

        # æŸ¥æ‰¾â€œåˆ°åº“æ—¶é—´â€
        arrive_time = ""
        container_div = span.find_parent("div")
        if container_div:
            time_pair = container_div.find_all("p", class_="more_massage")
            for p in time_pair:
                label = p.find("span", class_="SpanTitleLang")
                value = p.find("span", class_="SpanTextLang")
                if label and "åˆ°åº“æ—¶é—´" in label.text and value:
                    arrive_time = value.text.strip()
                    break

        # âœ… Debug è¾“å‡º
        print(f"ğŸ“¦ å•å·: {tracking} | é‡é‡: {weight} | åˆ°åº“æ—¶é—´: {arrive_time}")

        records.append({
            "å¿«é€’å•å·": tracking,
            "é‡é‡ï¼ˆkgï¼‰": weight,
            "è°çš„å¿«é€’": "",
            "åˆ°åº“æ—¶é—´": arrive_time
        })
    return pd.DataFrame(records)

# ========== åˆå¹¶æ–°å¢æ•°æ® ==========
def update_main_sheet(new_df):
    client = get_gsheet()
    sheet = client.open(SPREADSHEET_NAME).worksheet(MAIN_SHEET)
    existing = pd.DataFrame(sheet.get_all_records())

    if existing.empty:
        existing = pd.DataFrame(columns=["å¿«é€’å•å·", "é‡é‡ï¼ˆkgï¼‰", "è°çš„å¿«é€’", "åˆ°åº“æ—¶é—´"])

    existing["å¿«é€’å•å·"] = existing["å¿«é€’å•å·"].astype(str)
    new_df["å¿«é€’å•å·"] = new_df["å¿«é€’å•å·"].astype(str)

    existing_ids = set(existing["å¿«é€’å•å·"])
    new_entries = new_df[~new_df["å¿«é€’å•å·"].isin(existing_ids)]

    print(f"ğŸ“¦ æŠ“å–åˆ°çš„æ‰€æœ‰å•å·ï¼š {list(new_df['å¿«é€’å•å·'])}")
    print(f"ğŸ“„ è¡¨ä¸­å·²æœ‰å•å·ï¼š {list(existing['å¿«é€’å•å·'])}")

    if new_entries.empty:
        print("ğŸ“­ æ²¡æœ‰æ–°å¢è®°å½•ï¼Œè·³è¿‡æ›´æ–° âœ…")
        return

    updated = pd.concat([existing, new_entries], ignore_index=True)
    updated = updated[["å¿«é€’å•å·", "é‡é‡ï¼ˆkgï¼‰", "è°çš„å¿«é€’", "åˆ°åº“æ—¶é—´"]]
    sheet.clear()
    sheet.update([updated.columns.values.tolist()] + updated.values.tolist())
    print(f"âœ… å·²æ–°å¢ {len(new_entries)} æ¡è®°å½•ï¼Œå¹¶æ›´æ–° Google Sheets âœ…")

# ========== ä¸»æµç¨‹ ==========
def main():
    print("ğŸšš æŠ“å–å¿«é€’æ•°æ®ä¸­...")
    df = fetch_packages()
    print(f"ğŸ“¦ å…±è·å– {len(df)} æ¡å¿«é€’è®°å½•")
    if df.empty:
        print("âš ï¸ æœªæŠ“å–åˆ°ä»»ä½•è®°å½•ï¼Œè¯·æ£€æŸ¥ Cookie æˆ–é¡µé¢ç»“æ„")
        return
    update_main_sheet(df)
    print("âœ… Google Sheets å·²æ›´æ–°")

if __name__ == "__main__":
    main()
