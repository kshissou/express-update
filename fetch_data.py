import os
import re
import json
import requests
import pandas as pd
from bs4 import BeautifulSoup
from datetime import datetime
from dotenv import load_dotenv
import gspread
from google.oauth2.service_account import Credentials

load_dotenv()

def fetch_packages():
    print("ğŸšš æŠ“å–å¿«é€’æ•°æ®ä¸­...")

    url = "https://www.yuanriguoji.com/Package/Package_Select_Package.aspx"

    headers = {
        "User-Agent": "Mozilla/5.0",
        "Cookie": os.environ["YUANRI_COOKIE"]
    }

    response = requests.get(url, headers=headers)
    response.encoding = 'utf-8'

    if response.status_code != 200:
        print(f"âŒ é¡µé¢è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}")
        return pd.DataFrame()

    soup = BeautifulSoup(response.text, "html.parser")
    rows = soup.find_all("tr", attrs={"class": "gridview_items"})

    data = []
    for row in rows:
        tracking_tag = row.find("span", attrs={"name": "BillCode"})
        weight_tag = row.find_all("td")[8]  # é‡é‡åœ¨ç¬¬9åˆ—ï¼ˆä»0å¼€å§‹ï¼‰
        arrival_tag = row.find("span", class_="SpanTitleLang", string="åˆ°åº“æ—¶é—´")

        if tracking_tag:
            tracking = tracking_tag.text.strip()
            try:
                weight = float(weight_tag.text.strip().replace("kg", "").strip())
            except:
                weight = ""
            # æŸ¥æ‰¾ç›¸é‚»çš„åˆ°åº“æ—¶é—´
            arrival_time = ""
            if arrival_tag:
                span_text = arrival_tag.find_next_sibling("span", class_="SpanTextLang")
                if span_text:
                    arrival_time = span_text.text.strip()
            data.append({
                "å¿«é€’å•å·": tracking,
                "é‡é‡ï¼ˆkgï¼‰": weight,
                "è°çš„å¿«é€’": "",
                "åˆ°åº“æ—¶é—´": arrival_time
            })

    df = pd.DataFrame(data)
    print(f"ğŸ“¦ å…±è·å– {len(df)} æ¡å¿«é€’è®°å½•")
    return df

def get_gsheet():
    json_str = os.environ["GOOGLE_APPLICATION_CREDENTIALS_JSON"]
    credentials_dict = json.loads(json_str)
    scopes = ["https://www.googleapis.com/auth/spreadsheets"]
    credentials = Credentials.from_service_account_info(credentials_dict, scopes=scopes)
    gc = gspread.authorize(credentials)
    return gc

def update_main_sheet(new_df):
    if new_df.empty:
        print("âš ï¸ æœªæŠ“å–åˆ°ä»»ä½•è®°å½•ï¼Œè¯·æ£€æŸ¥ Cookie æˆ–é¡µé¢ç»“æ„")
        return

    gc = get_gsheet()
    sh = gc.open_by_url("https://docs.google.com/spreadsheets/d/1F28X2UHHb7iCVJWZ1FO4X7-FRkUrRhsikZ3BFmFZr5o/edit")
    worksheet = sh.sheet1
    data = worksheet.get_all_records()
    old_df = pd.DataFrame(data)
    old_df["å¿«é€’å•å·"] = old_df["å¿«é€’å•å·"].astype(str)

    new_df["å¿«é€’å•å·"] = new_df["å¿«é€’å•å·"].astype(str)
    existing_ids = set(old_df["å¿«é€’å•å·"])
    all_ids = set(new_df["å¿«é€’å•å·"])

    print(f"ğŸ“¦ æŠ“å–åˆ°çš„æ‰€æœ‰å•å·ï¼š {list(new_df['å¿«é€’å•å·'])}")
    print(f"ğŸ“„ è¡¨ä¸­å·²æœ‰å•å·ï¼š {list(old_df['å¿«é€’å•å·'])}")

    new_entries = new_df[~new_df["å¿«é€’å•å·"].isin(existing_ids)]
    if new_entries.empty:
        print("ğŸ“­ æ²¡æœ‰æ–°å¢è®°å½•ï¼Œè·³è¿‡æ›´æ–° âœ…")
    else:
        updated_df = pd.concat([old_df, new_entries], ignore_index=True)
        worksheet.clear()
        worksheet.update([updated_df.columns.tolist()] + updated_df.values.tolist())
        print(f"âœ… å·²æ–°å¢ {len(new_entries)} æ¡è®°å½•ï¼Œå¹¶æ›´æ–° Google Sheets âœ…")

    print("âœ… Google Sheets å·²æ›´æ–°")

def main():
    df = fetch_packages()
    update_main_sheet(df)

if __name__ == "__main__":
    main()
